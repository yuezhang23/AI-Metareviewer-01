{"task": "metareviewer", "data_dir": "data/", "prompts": "prompts/metareview.md", "out": "results/mr-eval240-c1.5.out", "max_threads": 8, "temperature": 0.0, "expansion_temperature": 0.6, "optimizer": "nl-gradient", "rounds": 4, "beam_size": 4, "n_test_exs": 200, "minibatch_size": 64, "n_gradients": 4, "errors_per_gradient": 4, "gradients_per_error": 1, "steps_per_gradient": 1, "mc_samples_per_step": 2, "max_expansion_factor": 8, "engine": "chatgpt", "evaluator": "ucb", "scorer": "01", "eval_rounds": 3, "eval_prompts_per_round": 8, "samples_per_eval": 10, "c": 1.5, "knn_k": 2, "knn_t": 0.993, "reject_on_errors": false, "eval_budget": 240}
---- eva budget ; 240 - "eval_rounds": 3, "eval_prompts_per_round": 8, "samples_per_eval": 10, c : 1.5
---- test size : 200 
---- beam_size = 4

---- Rounds : 3 ----------------------------------------------------
Qt scores - UCB : [0.9, 0.9, 0.8, 0.8] 

Experiment 1 ----- 0 replicates, 4 trials 

# 4 trials of F1s 
[0.750, 0.679, 0.531, 0.793]
[0.651, 0.671, 0.744, 0.600]
[0.645, 0.667, 0.643, 0.552]
[0.671, 0.774, 0.556, 0.667] 
# mean 
F1 : [0.679, 0.697, 0.618, 0.653]

Experiment 2 ----- 5 replicates on majority voting, 1 Trial
F1 : [0.62, 0.635, 0.62, 0.635]


---- Rounds : 4 ----------------------------------------------------
Qt scores - UCB : [0.8, 0.8, 0.75, 0.75] 

Experiment 1 ----- 0 replicates, 4 trials

# 4 trialss of F1s 
[0.741, 0.700, 0.613, 0.815],
[0.741, 0.567, 0.607, 0.750],
[0.692, 0.630, 0.517, 0.500],
[0.792, 0.640, 0.481, 0.720]
# mean 
F1 : [0.741, 0.634, 0.555, 0.696]

Experiment 2 -----  5 replicates on majority voting, 1 Trial
F1 : [0.645, 0.645, 0.535, 0.535]

